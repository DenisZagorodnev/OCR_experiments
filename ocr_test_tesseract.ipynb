{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import json\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import copy\n",
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import glob\n",
    "import tabula\n",
    "import PyPDF2\n",
    "from pdf2image import convert_from_path\n",
    "#import textract\n",
    "import csv\n",
    "from pytesseract import image_to_string\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "import cv2\n",
    "from skimage import io\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(img):\n",
    "    h, w = img.shape\n",
    "    boxes = pytesseract.image_to_boxes(img) \n",
    "    for b in boxes.splitlines():\n",
    "        b = b.split(' ')\n",
    "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('img', words_pack_1)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = proc_img('./ocr_experiments/words_pack_1.png')\n",
    "\n",
    "# get_boxes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_img(img_path):\n",
    "    \n",
    "    words_pack_1 = io.imread(img_path)\n",
    "    \n",
    "    #words_pack_1 = remove_noise(words_pack_1)\n",
    "    \n",
    "    gray = get_grayscale(words_pack_1)\n",
    "\n",
    "    words_pack_1 = thresholding(gray)\n",
    "\n",
    "    #words_pack_1 = opening(treshholded)\n",
    "\n",
    "    #words_pack_1 = canny(opened)\n",
    "    \n",
    "    return words_pack_1\n",
    "\n",
    "\n",
    "def calc_qual(img_path, data_path):\n",
    "    \n",
    "    words_pack_origin_1 = pd.read_excel(data_path)\n",
    "\n",
    "    words_pack_origin_1 = list(words_pack_origin_1['header_1'].apply(lambda x: re.sub('\\xa0', '', x)))\n",
    "    \n",
    "    \n",
    "    words_pack_1 = proc_img(img_path)\n",
    "    \n",
    "    text = image_to_string(words_pack_1, lang = 'rus').split()\n",
    "    \n",
    "    percent = len(list(set(text) & set(words_pack_origin_1)))/len(words_pack_origin_1)\n",
    "    \n",
    "    return text, percent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pack_1_path = './ocr_experiments/words_pack_1.png'\n",
    "\n",
    "words_pack_origin_1 =  './ocr_experiments/words_pack_origin_1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, perc = calc_qual(words_pack_1_path, words_pack_origin_1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пороть',\n",
       " 'орераы',\n",
       " 'адоуриит',\n",
       " 'аАвеновия.',\n",
       " 'оАвлодл',\n",
       " 'ваьдавитее”',\n",
       " 'одлтинау',\n",
       " 'Фолллвдиие',\n",
       " 'длыируфон',\n",
       " 'аеауоче',\n",
       " 'оиааия',\n",
       " 'олемар',\n",
       " 'один',\n",
       " 'пиар',\n",
       " 'омеротау',\n",
       " 'види',\n",
       " 'дру',\n",
       " 'бури',\n",
       " 'РАЯ',\n",
       " 'сори',\n",
       " 'им']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
